{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core \n",
        "print(azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.20.0\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1611606755952
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.environment import Environment\n",
        "Environment(name=\"vaenv\")\n",
        "myenv = Environment(name=\"vaenv\")"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1611606756193
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "dependencies = CondaDependencies()\n",
        "dependencies.add_pip_package(\"scikit-learn\")\n",
        "dependencies.add_pip_package(\"numpy==1.15.4\")\n",
        "myenv.python.conda_dependencies=dependencies"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1611606756395
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "\n",
        "ws = Workspace.get(name='Toria_workspace',\n",
        "            subscription_id='784d8740-4c70-4d20-8f45-b2bfecf94029',\n",
        "            resource_group='myresourcegroup',)\n",
        "exp = Experiment(workspace=ws, name=\"Toria_workspace\")\n",
        "\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
        "\n",
        "run = exp.start_logging()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workspace name: Toria_workspace\n",
            "Azure region: eastus2\n",
            "Subscription id: 784d8740-4c70-4d20-8f45-b2bfecf94029\n",
            "Resource group: myresourcegroup\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1611606762965
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "\n",
        "# TODO: Create compute cluster\n",
        "# Use vm_size = \"Standard_D2_V2\" in your provisioning configuration.\n",
        "# max_nodes should be no greater than 4.\n",
        "compute_target_name = \"vpacompute\"\n",
        "compute_cluster = AmlCompute.provisioning_configuration(vm_size = \"Standard_D2_V2\", max_nodes = 4)\n",
        "my_target =  ComputeTarget.create(ws, compute_target_name, compute_cluster)\n",
        "### YOUR CODE HERE ###"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1611606763411
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import csv\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import datasets\n",
        "import pkg_resources\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.20.0\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1611606763638
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "## \n",
        "This dataset contains information of a growing customer base of a bank. With majority of it's customers being depositors with \n",
        "varying size of deposits. In this project, I will be using Automated ML with a classification task to predict the likelihood \n",
        "of a liability customer buying personal loans\n",
        "\n",
        "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing.\n",
        "\n",
        "\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "\n",
        "# Create TabularDataset using TabularDatasetFactory\n",
        "# Data is available at: \n",
        "dat = \"https://raw.githubusercontent.com/vikkyfama/Project_Capstone/toribranch/Personal_loans.csv\"\n",
        "ds = TabularDatasetFactory.from_delimited_files(dat)\n",
        "print(ds)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TabularDataset\n",
            "{\n",
            "  \"source\": [\n",
            "    \"https://raw.githubusercontent.com/vikkyfama/Project_Capstone/toribranch/Personal_loans.csv\"\n",
            "  ],\n",
            "  \"definition\": [\n",
            "    \"GetFiles\",\n",
            "    \"ParseDelimited\",\n",
            "    \"DropColumns\",\n",
            "    \"SetColumnTypes\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1611606767500
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import sparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from azureml.core.dataset import Dataset\n",
        "import numpy as np\n",
        "from traintest2 import clean_data\n",
        "#from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "x, y = clean_data(ds)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Experience 20.1046\n",
            "Average Experience 20.1046\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1611606769502
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import sparse\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import datasets\n",
        "from azureml.core.dataset import Dataset\n",
        "import numpy as np\n",
        "#from train import clean_data\n",
        "#from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "from sklearn import preprocessing\n",
        "import os\n",
        "\n",
        "\n",
        "#x_train, x_test, y_train, y_test = train_test_split(P_loan, test_size = 0.3, random_state = 0)\n",
        "#x_train, x_test, y_train, y_test\n",
        "training_data = pd.concat([x_train, y_train], axis = 1)\n",
        "\n",
        "if not os.path.isdir('dataset'):\n",
        "    os.mkdir('dataset')\n",
        "\n",
        "\n",
        "training_data.to_csv('dataset/loan.csv')\n",
        "ds = ws.get_default_datastore()\n",
        "ds.upload(src_dir='./dataset', target_path='loandataset', overwrite=True, show_progress=True)\n",
        "\n",
        "training_data = Dataset.Tabular.from_delimited_files(path=ds.path('loandataset/loan.csv'))\n",
        "training_data"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading an estimated of 1 files\n",
            "Uploading ./dataset/loan.csv\n",
            "Uploaded ./dataset/loan.csv, 1 files out of an estimated total of 1\n",
            "Uploaded 1 files\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "{\n  \"source\": [\n    \"('workspaceblobstore', 'loandataset/loan.csv')\"\n  ],\n  \"definition\": [\n    \"GetDatastoreFiles\",\n    \"ParseDelimited\",\n    \"DropColumns\",\n    \"SetColumnTypes\"\n  ]\n}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1611606772168
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "# choose a name for experiment\n",
        "experiment_name = 'People_loan_experiment'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1611606772836
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML settings\n",
        "For the AutoMLsettings, I specified an experiment_timeout_hours to 0.3 so as to terminate the experiment when this value is reached.\n",
        "setting enable_early stop to be true whenever the score is not improving in the short term, the iteration_timeout_minutes was set to 5 which is the maximum time for each iteration to run before it terminates. \n",
        "Max_concurrent_iterations was set to 4 which was the number of iterations that would be executed in parallel\n",
        "For the primary_metric I chose the AUC_Weighted because its better at optimizing datasets which are very small and have very large class skew (clasmay not optimize as well for datasets which are very small and have very large class skew (class imbalance). \n",
        "Featurization is set to 'auto'so as to allow featurization to be done automatically.\n",
        "\n",
        "## AutoML Configuration\n",
        "For the AutoML Configuration, I chose the classification task because i am trying to predict which category an existing customer will fall into based on learnings from its training data.\n",
        "The training_data is the resulting data from the already split data after it had been converted to a tabular dataset which is what is accepted by autoML.\n",
        "Label_column_name is the 'Personal loan' which is the column we are trying to predict.\n",
        "n_cross_validation is set to 5 which is the number of cross validations to perform.\n",
        "\n",
        "TODO: Explain why you chose the automl settings and cofiguration you used below.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Put your automl settings here\n",
        "automl_settings = {\n",
        "     \"experiment_timeout_hours\" : 0.3,\n",
        "    \"enable_early_stopping\" : True,\n",
        "    \"iteration_timeout_minutes\": 5,\n",
        "    \"max_concurrent_iterations\": 4,\n",
        "    \"primary_metric\": 'AUC_weighted',\n",
        "    \"featurization\": 'auto',\n",
        "}\n",
        "\n",
        "# TODO: Put your automl config here\n",
        "automl_config = AutoMLConfig(\n",
        "    compute_target = 'vpacompute',\n",
        "    task=\"classification\",\n",
        "    training_data= training_data,\n",
        "    label_column_name= \"Personal Loan\",\n",
        "    n_cross_validations=5\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1611606773015
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Submit your experiment\n",
        "#remote_run = experiment.submit(automl_config)\n",
        "remote_run = experiment.submit(automl_config, show_output = True)\n",
        "remote_run"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on remote.\n",
            "No run_configuration provided, running on vpacompute with default configuration\n",
            "Running on remote compute: vpacompute\n",
            "Parent Run ID: AutoML_d26f0cc7-9605-402e-9480-92002a6f696a\n",
            "\n",
            "Current status: FeaturesGeneration. Generating features for the dataset.\n",
            "Current status: ModelSelection. Beginning model selection.\n",
            "\n",
            "****************************************************************************************************\n",
            "DATA GUARDRAILS: \n",
            "\n",
            "TYPE:         Class balancing detection\n",
            "STATUS:       ALERTED\n",
            "DESCRIPTION:  To decrease model bias, please cancel the current run and fix balancing problem.\n",
            "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
            "DETAILS:      Imbalanced data can lead to a falsely perceived positive effect of a model's accuracy because the input data has bias towards one class.\n",
            "+---------------------------------+---------------------------------+--------------------------------------+\n",
            "|Size of the smallest class       |Name/Label of the smallest class |Number of samples in the training data|\n",
            "+=================================+=================================+======================================+\n",
            "|346                              |1                                |3750                                  |\n",
            "+---------------------------------+---------------------------------+--------------------------------------+\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "TYPE:         Missing feature values imputation\n",
            "STATUS:       PASSED\n",
            "DESCRIPTION:  No feature missing values were detected in the training data.\n",
            "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "TYPE:         High cardinality feature detection\n",
            "STATUS:       PASSED\n",
            "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
            "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "****************************************************************************************************\n",
            "ITERATION: The iteration being evaluated.\n",
            "PIPELINE: A summary description of the pipeline being evaluated.\n",
            "DURATION: Time taken for the current iteration.\n",
            "METRIC: The result of computing score on the fitted pipeline.\n",
            "BEST: The best observed score thus far.\n",
            "****************************************************************************************************\n",
            "\n",
            " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
            "         0   MaxAbsScaler LightGBM                          0:00:47       0.9861    0.9861\n",
            "         1   MaxAbsScaler XGBoostClassifier                 0:00:48       0.9848    0.9861\n",
            "         2   MaxAbsScaler RandomForest                      0:00:48       0.9611    0.9861\n",
            "         3   MaxAbsScaler RandomForest                      0:00:50       0.9264    0.9861\n",
            "         4   MaxAbsScaler RandomForest                      0:00:46       0.9427    0.9861\n",
            "         5   MaxAbsScaler RandomForest                      0:00:45       0.8421    0.9861\n",
            "         6   SparseNormalizer XGBoostClassifier             0:00:42       0.9592    0.9861\n",
            "         7   MaxAbsScaler GradientBoosting                  0:00:50       0.9656    0.9861\n",
            "         8   MaxAbsScaler ExtremeRandomTrees                0:00:51       0.9077    0.9861\n",
            "         9   MaxAbsScaler LogisticRegression                0:00:52       0.9635    0.9861\n",
            "        10   StandardScalerWrapper RandomForest             0:00:46       0.9272    0.9861\n",
            "        11   SparseNormalizer XGBoostClassifier             0:00:53       0.9563    0.9861\n",
            "        12   MaxAbsScaler LightGBM                          0:00:53       0.9789    0.9861\n",
            "        13   StandardScalerWrapper LightGBM                 0:00:45       0.9077    0.9861\n",
            "        14   MaxAbsScaler LightGBM                          0:00:47       0.9843    0.9861\n",
            "        15   MaxAbsScaler LightGBM                          0:00:52       0.9496    0.9861\n",
            "        16   SparseNormalizer XGBoostClassifier             0:00:56       0.9539    0.9861\n",
            "        17   MaxAbsScaler RandomForest                      0:01:05       0.9675    0.9861\n",
            "        18   MaxAbsScaler LightGBM                          0:00:46       0.9077    0.9861\n",
            "        19   StandardScalerWrapper LightGBM                 0:01:06       0.9832    0.9861\n",
            "        20   StandardScalerWrapper XGBoostClassifier        0:00:51       0.9813    0.9861\n",
            "        21   SparseNormalizer XGBoostClassifier             0:00:57       0.9456    0.9861\n",
            "        22   SparseNormalizer XGBoostClassifier             0:00:59       0.9659    0.9861\n",
            "        23   MaxAbsScaler LightGBM                          0:00:53       0.9363    0.9861\n",
            "        24   SparseNormalizer XGBoostClassifier             0:00:55       0.9616    0.9861\n",
            "        25   SparseNormalizer LightGBM                      0:00:50       0.9357    0.9861\n",
            "        26   StandardScalerWrapper XGBoostClassifier        0:00:55       0.9739    0.9861\n",
            "        27   SparseNormalizer XGBoostClassifier             0:00:50       0.9587    0.9861\n",
            "        28   SparseNormalizer XGBoostClassifier             0:00:56       0.9488    0.9861\n",
            "        29   SparseNormalizer XGBoostClassifier             0:00:43       0.9560    0.9861\n",
            "        30    VotingEnsemble                                0:01:20       0.9867    0.9867\n",
            "        31    StackEnsemble                                 0:01:21       0.9856    0.9867\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "Run(Experiment: People_loan_experiment,\nId: AutoML_d26f0cc7-9605-402e-9480-92002a6f696a,\nType: automl,\nStatus: Completed)",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>People_loan_experiment</td><td>AutoML_d26f0cc7-9605-402e-9480-92002a6f696a</td><td>automl</td><td>Completed</td><td><a href=\"https://ml.azure.com/experiments/People_loan_experiment/runs/AutoML_d26f0cc7-9605-402e-9480-92002a6f696a?wsid=/subscriptions/784d8740-4c70-4d20-8f45-b2bfecf94029/resourcegroups/myresourcegroup/workspaces/toria_workspace\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/overview/azure/ml/intro?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1611609556144
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "\n",
        "RunDetails(remote_run).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1611609556595
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.environment import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "# to install required packages\n",
        "env = Environment('vfenv')\n",
        "cd = CondaDependencies.create(pip_packages=['azureml-sdk','azureml-dataset-runtime[pandas,fuse]', 'azureml-defaults'], conda_packages = ['scikit-learn==0.22.1', 'scikit-learn'])\n",
        "#azureml-sdk\", \"azureml-dataprep[fuse,pandas]\", \"azureml-defaults>=1.0.45\n",
        "env.python.conda_dependencies = cd\n",
        "#cd.add_conda_package(\"scikit-learn\")\n",
        "# Register environment to re-use later\n",
        "env.register(workspace = ws)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 52,
          "data": {
            "text/plain": "{\n    \"databricks\": {\n        \"eggLibraries\": [],\n        \"jarLibraries\": [],\n        \"mavenLibraries\": [],\n        \"pypiLibraries\": [],\n        \"rcranLibraries\": []\n    },\n    \"docker\": {\n        \"arguments\": [],\n        \"baseDockerfile\": null,\n        \"baseImage\": \"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210104.v1\",\n        \"baseImageRegistry\": {\n            \"address\": null,\n            \"password\": null,\n            \"registryIdentity\": null,\n            \"username\": null\n        },\n        \"enabled\": false,\n        \"platform\": {\n            \"architecture\": \"amd64\",\n            \"os\": \"Linux\"\n        },\n        \"sharedVolumes\": true,\n        \"shmSize\": null\n    },\n    \"environmentVariables\": {\n        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n    },\n    \"inferencingStackVersion\": null,\n    \"name\": \"vfenv\",\n    \"python\": {\n        \"baseCondaEnvironment\": null,\n        \"condaDependencies\": {\n            \"channels\": [\n                \"anaconda\",\n                \"conda-forge\"\n            ],\n            \"dependencies\": [\n                \"python=3.6.2\",\n                {\n                    \"pip\": [\n                        \"azureml-sdk~=1.20.0\",\n                        \"azureml-dataset-runtime[pandas,fuse]~=1.20.0\",\n                        \"azureml-defaults~=1.20.0\"\n                    ]\n                },\n                \"scikit-learn==0.22.1\",\n                \"scikit-learn\"\n            ],\n            \"name\": \"azureml_cbb7c564e28cb7a13cffdc8c4f3bd2d7\"\n        },\n        \"condaDependenciesFile\": null,\n        \"interpreterPath\": \"python\",\n        \"userManagedDependencies\": false\n    },\n    \"r\": null,\n    \"spark\": {\n        \"packages\": [],\n        \"precachePackages\": true,\n        \"repositories\": []\n    },\n    \"version\": \"3\"\n}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 52,
      "metadata": {
        "gather": {
          "logged": 1611611963191
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run, best_model = remote_run.get_output()\n",
        "#print(best_run)\n",
        "#print(best_model)\n",
        "#best_run, best_model = remote_run.get_output()\n",
        "#best_run, best_model\n",
        "best_run.id\n",
        "\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 77,
          "data": {
            "text/plain": "'AutoML_d26f0cc7-9605-402e-9480-92002a6f696a_30'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 77,
      "metadata": {
        "gather": {
          "logged": 1611648413193
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Save the best model\n",
        "import joblib\n",
        "#joblib.dump(best_model,'best_aut_model.pkl')\n",
        "\n",
        "\n",
        "\n",
        "#filename = 'outputs/best_aut_model.joblib'\n",
        "joblib.dump(best_model, 'best_remoterun_model.pkl')\n",
        "\n",
        "#print(filename)\n",
        "\n",
        "#import joblib\n",
        "#joblib.dump(value=fmodel, filename='model.pkl')"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 78,
          "data": {
            "text/plain": "['best_remoterun_model.pkl']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 78,
      "metadata": {
        "gather": {
          "logged": 1611648470147
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import Model\n",
        "\n",
        "#model = best_model.register_model(model_name = 'best_aut_model', model_path = './outputs/')\n",
        "\n",
        "#from azureml.core.model import Model\n",
        "\n",
        "model = Model.register(model_path= 'best_remoterun_model.pkl',\n",
        "                       model_name=\"best_remoterun_model\",\n",
        "                       tags={\"data\": \"loans\",  \"method\" : \"sklearn\"},\n",
        "                       description=\"Predict loans with sklearn\",\n",
        "                       workspace=ws)\n",
        "print(model)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registering model best_remoterun_model\n",
            "Model(workspace=Workspace.create(name='toria_workspace', subscription_id='784d8740-4c70-4d20-8f45-b2bfecf94029', resource_group='myresourcegroup'), name=best_remoterun_model, id=best_remoterun_model:2, version=2, tags={'data': 'loans', 'method': 'sklearn'}, properties={})\n"
          ]
        }
      ],
      "execution_count": 114,
      "metadata": {
        "gather": {
          "logged": 1611658907729
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Environment\r\n",
        "\r\n",
        "ws = Workspace.from_config()\r\n",
        "env = Environment.get(workspace=ws, name=\"AzureML-AutoML\")\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": 119,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611659540170
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.automl.core.shared import constants\r\n",
        "best_run.download_file(constants.CONDA_ENV_FILE_PATH, 'env.yml')"
      ],
      "outputs": [],
      "execution_count": 129,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611661402832
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.environment import Environment\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "\r\n",
        "env = Environment(name=\"vfenv\")\r\n",
        "conda_dep = CondaDependencies()\r\n",
        "\r\n",
        "# Installs numpy version 1.17.0 conda package\r\n",
        "conda_dep.add_conda_package(\"numpy==1.18.0\")\r\n",
        "\r\n",
        "# Installs pillow package\r\n",
        "conda_dep.add_pip_package(\"pillow\")\r\n",
        "\r\n",
        "# Adds dependencies to PythonSection of myenv\r\n",
        "myenv.python.conda_dependencies=conda_dep"
      ],
      "outputs": [],
      "execution_count": 89,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611656499033
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "envs = Environment.list(workspace=ws)\r\n",
        "\r\n",
        "for env in envs:\r\n",
        "    if env.startswith(\"AzureML-AutoML\"):\r\n",
        "        print(\"Name\",env)\r\n",
        "        print(\"packages\", envs[env].python.conda_dependencies.serialize_to_string())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name AzureML-AutoML\n",
            "packages channels:\n",
            "- anaconda\n",
            "- conda-forge\n",
            "- pytorch\n",
            "dependencies:\n",
            "- python=3.6.2\n",
            "- pip=20.2.4\n",
            "- pip:\n",
            "  - azureml-core==1.20.0\n",
            "  - azureml-pipeline-core==1.20.0\n",
            "  - azureml-telemetry==1.20.0\n",
            "  - azureml-defaults==1.20.0\n",
            "  - azureml-interpret==1.20.0\n",
            "  - azureml-automl-core==1.20.0\n",
            "  - azureml-automl-runtime==1.20.0\n",
            "  - azureml-train-automl-client==1.20.0\n",
            "  - azureml-train-automl-runtime==1.20.0.post1\n",
            "  - azureml-dataset-runtime==1.20.0\n",
            "  - inference-schema\n",
            "  - py-cpuinfo==5.0.0\n",
            "  - boto3==1.15.18\n",
            "  - botocore==1.18.18\n",
            "- numpy~=1.18.0\n",
            "- scikit-learn==0.22.1\n",
            "- pandas~=0.25.0\n",
            "- py-xgboost<=0.90\n",
            "- fbprophet==0.5\n",
            "- holidays==0.9.11\n",
            "- setuptools-git\n",
            "- psutil>5.0.0,<6.0.0\n",
            "name: azureml_265db83b0c6014ce472c5de2f0b97e04\n",
            "\n",
            "Name AzureML-AutoML-GPU\n",
            "packages channels:\n",
            "- anaconda\n",
            "- conda-forge\n",
            "- pytorch\n",
            "dependencies:\n",
            "- python=3.6.2\n",
            "- pip=20.2.4\n",
            "- pip:\n",
            "  - azureml-core==1.20.0\n",
            "  - azureml-pipeline-core==1.20.0\n",
            "  - azureml-telemetry==1.20.0\n",
            "  - azureml-defaults==1.20.0\n",
            "  - azureml-interpret==1.20.0\n",
            "  - azureml-automl-core==1.20.0\n",
            "  - azureml-automl-runtime==1.20.0\n",
            "  - azureml-train-automl-client==1.20.0\n",
            "  - azureml-train-automl-runtime==1.20.0.post1\n",
            "  - azureml-dataset-runtime==1.20.0\n",
            "  - inference-schema\n",
            "  - py-cpuinfo==5.0.0\n",
            "  - boto3==1.15.18\n",
            "  - botocore==1.18.18\n",
            "- numpy~=1.18.0\n",
            "- scikit-learn==0.22.1\n",
            "- pandas~=0.25.0\n",
            "- fbprophet==0.5\n",
            "- holidays==0.9.11\n",
            "- setuptools-git\n",
            "- psutil>5.0.0,<6.0.0\n",
            "name: azureml_18d64f9caaa7ac9444829c2a6c6c53a4\n",
            "\n",
            "Name AzureML-AutoML-DNN-GPU\n",
            "packages channels:\n",
            "- anaconda\n",
            "- conda-forge\n",
            "- pytorch\n",
            "dependencies:\n",
            "- python=3.6.2\n",
            "- pip=20.2.4\n",
            "- pip:\n",
            "  - azureml-core==1.20.0\n",
            "  - azureml-pipeline-core==1.20.0\n",
            "  - azureml-telemetry==1.20.0\n",
            "  - azureml-defaults==1.20.0\n",
            "  - azureml-interpret==1.20.0\n",
            "  - azureml-automl-core==1.20.0\n",
            "  - azureml-automl-runtime==1.20.0\n",
            "  - azureml-train-automl-client==1.20.0\n",
            "  - azureml-train-automl-runtime==1.20.0.post1\n",
            "  - azureml-dataset-runtime==1.20.0\n",
            "  - inference-schema\n",
            "  - horovod==0.19.4\n",
            "  - fbprophet==0.5\n",
            "  - pytorch-transformers==1.0.0\n",
            "  - spacy==2.1.8\n",
            "  - https://aka.ms/automl-resources/packages/en_core_web_sm-2.1.0.tar.gz\n",
            "  - py-cpuinfo==5.0.0\n",
            "  - boto3==1.15.18\n",
            "  - botocore==1.18.18\n",
            "- numpy~=1.18.0\n",
            "- scikit-learn==0.22.1\n",
            "- pandas~=0.25.0\n",
            "- holidays==0.9.11\n",
            "- setuptools-git\n",
            "- pytorch=1.4.0\n",
            "- cudatoolkit=10.0.130\n",
            "- psutil>5.0.0,<6.0.0\n",
            "name: azureml_75e5522d759423ed534bd8b30db7d2d8\n",
            "\n",
            "Name AzureML-AutoML-DNN\n",
            "packages channels:\n",
            "- anaconda\n",
            "- conda-forge\n",
            "- pytorch\n",
            "dependencies:\n",
            "- python=3.6.2\n",
            "- pip=20.2.4\n",
            "- pip:\n",
            "  - azureml-core==1.20.0\n",
            "  - azureml-pipeline-core==1.20.0\n",
            "  - azureml-telemetry==1.20.0\n",
            "  - azureml-defaults==1.20.0\n",
            "  - azureml-interpret==1.20.0\n",
            "  - azureml-automl-core==1.20.0\n",
            "  - azureml-automl-runtime==1.20.0\n",
            "  - azureml-train-automl-client==1.20.0\n",
            "  - azureml-train-automl-runtime==1.20.0.post1\n",
            "  - azureml-dataset-runtime==1.20.0\n",
            "  - inference-schema\n",
            "  - pytorch-transformers==1.0.0\n",
            "  - spacy==2.1.8\n",
            "  - https://aka.ms/automl-resources/packages/en_core_web_sm-2.1.0.tar.gz\n",
            "  - py-cpuinfo==5.0.0\n",
            "  - boto3==1.15.18\n",
            "  - botocore==1.18.18\n",
            "- numpy~=1.18.0\n",
            "- scikit-learn==0.22.1\n",
            "- pandas~=0.25.0\n",
            "- py-xgboost<=0.90\n",
            "- fbprophet==0.5\n",
            "- holidays==0.9.11\n",
            "- setuptools-git\n",
            "- pytorch=1.4.0\n",
            "- cudatoolkit=10.0.130\n",
            "- psutil>5.0.0,<6.0.0\n",
            "name: azureml_0fa610eee8d0a5b15925e6959503249d\n",
            "\n",
            "Name AzureML-AutoML-DNN-Vision-GPU\n",
            "packages dependencies:\n",
            "- python=3.7\n",
            "- pip=20.2.4\n",
            "- pip:\n",
            "  - azureml-core==1.20.0\n",
            "  - azureml-dataset-runtime==1.20.0\n",
            "  - azureml-contrib-dataset==1.20.0\n",
            "  - azureml-telemetry==1.20.0\n",
            "  - azureml-automl-core==1.20.0\n",
            "  - azureml-automl-runtime==1.20.0\n",
            "  - azureml-train-automl-client==1.20.0\n",
            "  - azureml-defaults==1.20.0\n",
            "  - azureml-interpret==1.20.0\n",
            "  - azureml-train-automl-runtime==1.20.0.post1\n",
            "  - azureml-train-automl==1.20.0\n",
            "  - azureml-contrib-automl-dnn-vision==1.20.0\n",
            "name: azureml_71e34237546bf5b852eab0aa7476f707\n",
            "\n"
          ]
        }
      ],
      "execution_count": 117,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611659283433
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "from azureml.core.environment import Environment\n",
        "\n",
        "#environment = Environment(\"LocalDeploy\")\n",
        "env.python.conda_dependencies.add_pip_package(\"scikit-learn==0.22.1\".format(sklearn.__version__))\n",
        "\n",
        "#env.python.conda_dependencies.add_pip_package(\"sklearn\")\n",
        "#env.python.conda_dependencies.add_pip_package(\"azureml-defaults\")"
      ],
      "outputs": [],
      "execution_count": 121,
      "metadata": {
        "gather": {
          "logged": 1611659602887
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile score.py\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from azureml.core.model import Model\n",
        "#from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient, PublicAccess\n",
        "\n",
        "import azureml.automl.core\n",
        "from azureml.automl.core.shared import logging_utilities, log_server\n",
        "from azureml.telemetry import INSTRUMENTATION_KEY\n",
        "\n",
        "from inference_schema.schema_decorators import input_schema, output_schema\n",
        "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
        "from inference_schema.parameter_types.pandas_parameter_type import PandasParameterType\n",
        "\n",
        "\n",
        "input_sample = pd.DataFrame({\"Column1\": pd.Series([0], dtype=\"int64\"), \"Experience\": pd.Series([0.0], dtype=\"float64\"), \"Income\": pd.Series([0.0], dtype=\"float64\"), \"Family\": pd.Series([0], dtype=\"int64\"), \"CCAvg\": pd.Series([0.0], dtype=\"float64\"), \"Education\": pd.Series([0], dtype=\"int64\"), \"Mortgage\": pd.Series([0.0], dtype=\"float64\"), \"Securities Account\": pd.Series([0], dtype=\"int64\"), \"CD Account\": pd.Series([0], dtype=\"int64\")})\n",
        "output_sample = np.array([0])\n",
        "try:\n",
        "    log_server.enable_telemetry(INSTRUMENTATION_KEY)\n",
        "    log_server.set_verbosity('INFO')\n",
        "    logger = logging.getLogger('azureml.automl.core.scoring_script')\n",
        "except:\n",
        "    pass\n",
        "\n",
        "\n",
        "def init():\n",
        "    global model\n",
        "     #This name is model.id of model that we want to deploy deserialize the model file back\n",
        "    # into a sklearn model\n",
        "    model_path = os.path.join(os.getenv(\"AZUREML_MODEL_DIR\"), 'best_remoterun_model.pkl')\n",
        "    path = os.path.normpath(model_path)\n",
        "    path_split = path.split(os.sep)\n",
        "    log_server.update_custom_dimensions({'model_name': path_split[1], 'model_version': path_split[2]})\n",
        "    try:\n",
        "        logger.info(\"Loading model from path.\")\n",
        "        model = joblib.load(model_path)\n",
        "        logger.info(\"Loading successful.\")\n",
        "    except Exception as e:\n",
        "        logging_utilities.log_traceback(e, logger)\n",
        "        raise\n",
        "\n",
        "\n",
        "@input_schema('data', PandasParameterType(input_sample))\n",
        "@output_schema(NumpyParameterType(output_sample))\n",
        "def run(data):\n",
        "    try:\n",
        "        result = model.predict(data)\n",
        "        return json.dumps({\"result\": result.tolist()})\n",
        "    except Exception as e:\n",
        "        result = str(e)\n",
        "        return json.dumps({\"error\": result})"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting score.py\n"
          ]
        }
      ],
      "execution_count": 122,
      "metadata": {
        "gather": {
          "logged": 1611610910279
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import InferenceConfig\n",
        "\n",
        "inference_config = InferenceConfig(entry_script=\"score.py\",\n",
        "                                   environment=env)"
      ],
      "outputs": [],
      "execution_count": 123,
      "metadata": {
        "gather": {
          "logged": 1611659733651
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "  conda update -n base -c defaults conda"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1611609559615
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import LocalWebservice\n",
        "\n",
        "\n",
        "# This is optional, if not provided Docker will choose a random unused port.\n",
        "deployment_config = LocalWebservice.deploy_configuration()\n",
        "\n",
        "local_service = Model.deploy(ws, \"test\", [model], inference_config, deployment_config)\n",
        "\n",
        "local_service.wait_for_deployment()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading model best_remoterun_model:2 to /tmp/azureml_e2a5haiu/best_remoterun_model/2\n",
            "Generating Docker build context.\n",
            "Package creation Succeeded\n",
            "Logging into Docker registry viennaglobal.azurecr.io\n",
            "Logging into Docker registry viennaglobal.azurecr.io\n",
            "Building Docker image from Dockerfile...\n",
            "Step 1/5 : FROM viennaglobal.azurecr.io/azureml/azureml_1b9697d50bbbb35eb098c299c7ed3dd0\n",
            " ---> e21868753f04\n",
            "Step 2/5 : COPY azureml-app /var/azureml-app\n",
            " ---> b2f323a4dd7b\n",
            "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6Ijc4NGQ4NzQwLTRjNzAtNGQyMC04ZjQ1LWIyYmZlY2Y5NDAyOSIsInJlc291cmNlR3JvdXBOYW1lIjoibXlyZXNvdXJjZWdyb3VwIiwiYWNjb3VudE5hbWUiOiJ0b3JpYV93b3Jrc3BhY2UiLCJ3b3Jrc3BhY2VJZCI6IjU1ZDQ2Nzg0LTRkOTUtNGU0OC1hMjk1LWY4NDE3ZWU0YmIyZSJ9LCJtb2RlbHMiOnt9LCJtb2RlbHNJbmZvIjp7fX0= | base64 --decode > /var/azureml-app/model_config_map.json\n",
            " ---> Running in b6696ece6795\n",
            " ---> cc21fa758cc5\n",
            "Step 4/5 : RUN mv '/var/azureml-app/tmpwm64kx3g.py' /var/azureml-app/main.py\n",
            " ---> Running in f179437491ee\n",
            " ---> bfe7c6754dd6\n",
            "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
            " ---> Running in 78235abb7582\n",
            " ---> 72724480b985\n",
            "Successfully built 72724480b985\n",
            "Successfully tagged test:latest\n",
            "Container has been successfully cleaned up.\n",
            "Image sha256:d5132eeadb93108546d8d50ca3b1fb9a3dcde8fd640152f5a7e2a08e05b10887 successfully removed.\n",
            "Starting Docker container...\n",
            "Docker container running.\n",
            "Checking container health...\n",
            "Local webservice is running at http://localhost:32805\n"
          ]
        }
      ],
      "execution_count": 124,
      "metadata": {
        "gather": {
          "logged": 1611659850358
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, \n",
        "                                               memory_gb=1,\n",
        "                                               tags={\"data\": \"loans\",  \"method\" : \"sklearn\"},\n",
        "                                               description='Predict loans with sklearn'\n",
        "                                               )"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import AciWebservice\n",
        "aciconfig = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=4, enable_app_insights=True)"
      ],
      "outputs": [],
      "execution_count": 111,
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1611658358331
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#%%time\n",
        "#import uuid\n",
        "from azureml.core.webservice import Webservice\n",
        "from azureml.core.model import InferenceConfig\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core import Workspace\n",
        "from azureml.core.model import Model\n",
        "\n",
        "ws = Workspace.from_config()\n",
        "model = Model(ws, 'best_remoterun_model')\n",
        "\n",
        "\n",
        "#myEnv = Environment.get(workspace=ws, name=\"vfenv\", version=\"1\")\n",
        "inference_config = InferenceConfig(entry_script=\"score.py\", environment=env)\n",
        "\n",
        "service_name = 'besttoberun' #+ str(uuid.uuid4())[:4]\n",
        "service = Model.deploy(workspace=ws, \n",
        "                       name=service_name, \n",
        "                       models=[model], \n",
        "                       inference_config=inference_config, \n",
        "                       deployment_config=aciconfig)\n",
        "\n",
        "service.wait_for_deployment(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running...................................................................................\n",
            "Succeeded\n",
            "ACI service creation operation finished, operation \"Succeeded\"\n"
          ]
        }
      ],
      "execution_count": 126,
      "metadata": {
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611660485287
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(service.get_logs())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "execution_count": 113,
      "metadata": {
        "gather": {
          "logged": 1611658854278
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\r\n",
        "import json\r\n",
        "\r\n",
        "# URL for the web service, should be similar to:\r\n",
        "# 'http://8530a665-66f3-49c8-a953-b82a2d312917.eastus.azurecontainer.io/score'\r\n",
        "scoring_uri = 'http://6f524ec3-a118-48c8-9718-96ab0ed0a32d.eastus2.azurecontainer.io/score'\r\n",
        "# If the service is authenticated, set the key or token\r\n",
        "#key = ''\r\n",
        "\r\n",
        "# Two sets of data to score, so we get two results back\r\n",
        "data = {\"data\":\r\n",
        "        [\r\n",
        "          {\r\n",
        "            \"Column1\": 10,\r\n",
        "            \"Experience\": 10,\r\n",
        "            \"Income\": 81,\r\n",
        "            \"Family\": 3,\r\n",
        "            \"CCAvg\": 0.6,\r\n",
        "            \"Education\": 2,\r\n",
        "            \"Mortgage\": 104,\r\n",
        "            \"Securities Account\": 0,\r\n",
        "            \"CD Account\": 0\r\n",
        "          },\r\n",
        "          {\r\n",
        "            \"Column1\": 20,\r\n",
        "            \"Experience\": 21,\r\n",
        "            \"Income\": 193,\r\n",
        "            \"Family\": 2,\r\n",
        "            \"CCAvg\": 8.1,\r\n",
        "            \"Education\": 3,\r\n",
        "            \"Mortgage\": 0,\r\n",
        "            \"Securities Account\": 0,\r\n",
        "            \"CD Account\": 0\r\n",
        "          },\r\n",
        "      ]\r\n",
        "    }\r\n",
        "# Convert to JSON string\r\n",
        "input_data = json.dumps(data)\r\n",
        "with open(\"data.json\", \"w\") as _f:\r\n",
        "    _f.write(input_data)\r\n",
        "\r\n",
        "# Set the content type\r\n",
        "headers = {'Content-Type': 'application/json'}\r\n",
        "# If authentication is enabled, set the authorization header\r\n",
        "#headers['Authorization'] = f'Bearer {key}'\r\n",
        "\r\n",
        "# Make the request and display the response\r\n",
        "resp = requests.post(scoring_uri, input_data, headers=headers)\r\n",
        "print(resp.json())\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"result\": [0, 1]}\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1611750814871
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
